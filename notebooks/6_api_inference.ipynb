{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d6582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/6_api_inference.ipynb\n",
    "\"\"\"\n",
    "API Inference Notebook\n",
    "Example requests, response format, and integration tests for deployed model.\n",
    "\"\"\"\n",
    "\n",
    "# %% [markdown]\n",
    "# # API Inference Testing Notebook\n",
    "# \n",
    "# This notebook demonstrates how to:\n",
    "# 1. Test the Credit Risk Scoring API\n",
    "# 2. Make predictions with different feature sets\n",
    "# 3. Validate response formats\n",
    "# 4. Run integration tests\n",
    "# 5. Generate test reports\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Setup and Configuration\n",
    "\n",
    "# %%\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# %%\n",
    "# API Configuration\n",
    "API_BASE_URL = \"http://localhost:8001\"  # Change if your API runs on different port\n",
    "HEALTH_ENDPOINT = f\"{API_BASE_URL}/health\"\n",
    "PREDICT_ENDPOINT = f\"{API_BASE_URL}/predict\"\n",
    "MODEL_INFO_ENDPOINT = f\"{API_BASE_URL}/model-info\"\n",
    "\n",
    "# Test data configuration\n",
    "TEST_CASES_FILE = \"../tests/test_cases.json\"\n",
    "SAMPLE_PAYLOADS_FILE = \"../payloads/sample_payloads.json\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "import os\n",
    "os.makedirs(\"../payloads\", exist_ok=True)\n",
    "os.makedirs(\"../tests\", exist_ok=True)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Utility Functions\n",
    "\n",
    "# %%\n",
    "def print_json(data: Dict, title: str = None):\n",
    "    \"\"\"Pretty print JSON data\"\"\"\n",
    "    if title:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"{title}\")\n",
    "        print(f\"{'='*60}\")\n",
    "    print(json.dumps(data, indent=2))\n",
    "\n",
    "def test_health_endpoint():\n",
    "    \"\"\"Test API health endpoint\"\"\"\n",
    "    try:\n",
    "        response = requests.get(HEALTH_ENDPOINT, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print_json(data, \"Health Check Response\")\n",
    "            \n",
    "            # Check model status\n",
    "            if data.get(\"model_loaded\"):\n",
    "                print(\"‚úÖ Model is loaded and ready\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"‚ùå Model not loaded\")\n",
    "                return False\n",
    "        else:\n",
    "            print(f\"‚ùå Health check failed: {response.status_code}\")\n",
    "            return False\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(f\"‚ùå Cannot connect to API at {API_BASE_URL}\")\n",
    "        print(\"Make sure the API is running:\")\n",
    "        print(\"  docker-compose up -d\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Health check error: {e}\")\n",
    "        return False\n",
    "\n",
    "def get_model_info():\n",
    "    \"\"\"Get information about the loaded model\"\"\"\n",
    "    try:\n",
    "        response = requests.get(MODEL_INFO_ENDPOINT, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print_json(data, \"Model Information\")\n",
    "            \n",
    "            # Extract important info\n",
    "            features = data.get(\"features_required\", [])\n",
    "            if features:\n",
    "                print(f\"\\nüìã Model expects {len(features)} features:\")\n",
    "                for i, feature in enumerate(features, 1):\n",
    "                    print(f\"  {i:2d}. {feature}\")\n",
    "            \n",
    "            thresholds = data.get(\"risk_thresholds\", {})\n",
    "            if thresholds:\n",
    "                print(f\"\\n‚öñÔ∏è  Risk Thresholds:\")\n",
    "                for category, threshold in thresholds.items():\n",
    "                    print(f\"  - {category}: < {threshold}\")\n",
    "            \n",
    "            return data\n",
    "        else:\n",
    "            print(f\"‚ùå Model info failed: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Model info error: {e}\")\n",
    "        return None\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Initial API Health Check\n",
    "\n",
    "# %%\n",
    "# Test API connection\n",
    "print(\"Testing API connection...\")\n",
    "api_healthy = test_health_endpoint()\n",
    "\n",
    "if api_healthy:\n",
    "    # Get model information\n",
    "    model_info = get_model_info()\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  API not healthy. Please start the API first:\")\n",
    "    print(\"  docker-compose -f docker_compose_2.yml up -d\")\n",
    "    print(\"\\nThen run the next cell to continue...\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Create Sample Test Payloads\n",
    "\n",
    "# %%\n",
    "# Create sample payloads for testing\n",
    "sample_payloads = {\n",
    "    \"simple_test\": {\n",
    "        \"customer_id\": \"CUST_TEST_001\",\n",
    "        \"features\": {\n",
    "            \"Year_mean\": 2024.0,\n",
    "            \"Month_mean\": 6.0\n",
    "        }\n",
    "    },\n",
    "    \"low_risk_example\": {\n",
    "        \"customer_id\": \"CUST_LOW_001\",\n",
    "        \"features\": {\n",
    "            \"Year_mean\": 2023.0,\n",
    "            \"Month_mean\": 3.0\n",
    "        }\n",
    "    },\n",
    "    \"medium_risk_example\": {\n",
    "        \"customer_id\": \"CUST_MED_001\",\n",
    "        \"features\": {\n",
    "            \"Year_mean\": 2024.0,\n",
    "            \"Month_mean\": 8.0\n",
    "        }\n",
    "    },\n",
    "    \"high_risk_example\": {\n",
    "        \"customer_id\": \"CUST_HIGH_001\",\n",
    "        \"features\": {\n",
    "            \"Year_mean\": 2022.0,\n",
    "            \"Month_mean\": 11.0\n",
    "        }\n",
    "    },\n",
    "    \"edge_case_min\": {\n",
    "        \"customer_id\": \"EDGE_MIN\",\n",
    "        \"features\": {\n",
    "            \"Year_mean\": 2020.0,\n",
    "            \"Month_mean\": 1.0\n",
    "        }\n",
    "    },\n",
    "    \"edge_case_max\": {\n",
    "        \"customer_id\": \"EDGE_MAX\",\n",
    "        \"features\": {\n",
    "            \"Year_mean\": 2024.0,\n",
    "            \"Month_mean\": 12.0\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save sample payloads\n",
    "with open(SAMPLE_PAYLOADS_FILE, 'w') as f:\n",
    "    json.dump(sample_payloads, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Created {len(sample_payloads)} sample payloads in {SAMPLE_PAYLOADS_FILE}\")\n",
    "\n",
    "# Display sample payloads\n",
    "print(\"\\nüìã Sample Payloads:\")\n",
    "for name, payload in sample_payloads.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Customer: {payload['customer_id']}\")\n",
    "    print(f\"  Features: {payload['features']}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Test Predictions with Different Payloads\n",
    "\n",
    "# %%\n",
    "def make_prediction(payload: Dict) -> Dict:\n",
    "    \"\"\"Make a prediction using the API\"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = requests.post(\n",
    "            PREDICT_ENDPOINT,\n",
    "            json=payload,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        response_time = time.time() - start_time\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            data[\"response_time_ms\"] = round(response_time * 1000, 2)\n",
    "            data[\"status_code\"] = response.status_code\n",
    "            return data\n",
    "        else:\n",
    "            return {\n",
    "                \"error\": f\"API Error: {response.status_code}\",\n",
    "                \"detail\": response.text,\n",
    "                \"response_time_ms\": round(response_time * 1000, 2),\n",
    "                \"status_code\": response.status_code\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": f\"Request failed: {str(e)}\",\n",
    "            \"response_time_ms\": None,\n",
    "            \"status_code\": None\n",
    "        }\n",
    "\n",
    "# %%\n",
    "# Test all sample payloads\n",
    "print(\"Testing predictions with sample payloads...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for name, payload in sample_payloads.items():\n",
    "    print(f\"\\nüîç Testing: {name}\")\n",
    "    print(f\"  Customer: {payload['customer_id']}\")\n",
    "    \n",
    "    result = make_prediction(payload)\n",
    "    \n",
    "    if \"error\" in result:\n",
    "        print(f\"  ‚ùå Error: {result['error']}\")\n",
    "    else:\n",
    "        print(f\"  ‚úÖ Success!\")\n",
    "        print(f\"  ‚è±Ô∏è  Response time: {result.get('response_time_ms', 'N/A')}ms\")\n",
    "        print(f\"  üìä Probability: {result.get('probability', 'N/A'):.4f}\")\n",
    "        print(f\"  üéØ Class: {result.get('predicted_class', 'N/A')}\")\n",
    "        print(f\"  ‚ö†Ô∏è  Risk: {result.get('risk_category', 'N/A')}\")\n",
    "        print(f\"  üí° Recommendation: {result.get('recommendation', 'N/A')}\")\n",
    "        \n",
    "        # Store for analysis\n",
    "        all_results[name] = result\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Response Format Validation\n",
    "\n",
    "# %%\n",
    "# Define expected response schema\n",
    "EXPECTED_RESPONSE_SCHEMA = {\n",
    "    \"probability\": float,\n",
    "    \"predicted_class\": int,\n",
    "    \"risk_category\": str,\n",
    "    \"risk_score\": int,\n",
    "    \"recommendation\": str,\n",
    "    \"customer_id\": str,\n",
    "    \"model\": str,\n",
    "    \"timestamp\": str,\n",
    "    \"features_used\": list\n",
    "}\n",
    "\n",
    "def validate_response_format(response: Dict) -> List[str]:\n",
    "    \"\"\"Validate response against expected schema\"\"\"\n",
    "    errors = []\n",
    "    \n",
    "    for field, expected_type in EXPECTED_RESPONSE_SCHEMA.items():\n",
    "        if field not in response:\n",
    "            errors.append(f\"Missing required field: {field}\")\n",
    "        elif not isinstance(response[field], expected_type):\n",
    "            errors.append(f\"Field '{field}' has type {type(response[field])}, expected {expected_type}\")\n",
    "    \n",
    "    # Additional validation rules\n",
    "    if \"probability\" in response:\n",
    "        prob = response[\"probability\"]\n",
    "        if not (0 <= prob <= 1):\n",
    "            errors.append(f\"Probability {prob} not in range [0, 1]\")\n",
    "    \n",
    "    if \"predicted_class\" in response:\n",
    "        pred_class = response[\"predicted_class\"]\n",
    "        if pred_class not in [0, 1]:\n",
    "            errors.append(f\"Predicted class {pred_class} not in [0, 1]\")\n",
    "    \n",
    "    if \"risk_score\" in response:\n",
    "        score = response[\"risk_score\"]\n",
    "        if not (0 <= score <= 100):\n",
    "            errors.append(f\"Risk score {score} not in range [0, 100]\")\n",
    "    \n",
    "    return errors\n",
    "\n",
    "# %%\n",
    "# Validate all successful responses\n",
    "print(\"\\nüî¨ Validating Response Formats...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "validation_results = {}\n",
    "\n",
    "for name, result in all_results.items():\n",
    "    if \"error\" not in result:\n",
    "        errors = validate_response_format(result)\n",
    "        validation_results[name] = {\n",
    "            \"valid\": len(errors) == 0,\n",
    "            \"errors\": errors\n",
    "        }\n",
    "        \n",
    "        if errors:\n",
    "            print(f\"\\n‚ùå {name} - FAILED:\")\n",
    "            for error in errors:\n",
    "                print(f\"  - {error}\")\n",
    "        else:\n",
    "            print(f\"‚úÖ {name} - PASSED\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Performance Testing\n",
    "\n",
    "# %%\n",
    "def performance_test(num_requests: int = 10, payload: Dict = None):\n",
    "    \"\"\"Run performance test with multiple requests\"\"\"\n",
    "    if payload is None:\n",
    "        payload = sample_payloads[\"simple_test\"]\n",
    "    \n",
    "    print(f\"Running performance test with {num_requests} requests...\")\n",
    "    \n",
    "    response_times = []\n",
    "    status_codes = []\n",
    "    \n",
    "    for i in range(num_requests):\n",
    "        print(f\"  Request {i+1}/{num_requests}...\", end=\"\\r\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        response = requests.post(\n",
    "            PREDICT_ENDPOINT,\n",
    "            json=payload,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            timeout=10\n",
    "        )\n",
    "        response_time = time.time() - start_time\n",
    "        \n",
    "        response_times.append(response_time)\n",
    "        status_codes.append(response.status_code)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä Performance Results:\")\n",
    "    print(f\"  Total requests: {num_requests}\")\n",
    "    print(f\"  Successful: {status_codes.count(200)}\")\n",
    "    print(f\"  Failed: {len(status_codes) - status_codes.count(200)}\")\n",
    "    print(f\"  Avg response time: {np.mean(response_times)*1000:.2f}ms\")\n",
    "    print(f\"  Min response time: {np.min(response_times)*1000:.2f}ms\")\n",
    "    print(f\"  Max response time: {np.max(response_times)*1000:.2f}ms\")\n",
    "    print(f\"  Std dev: {np.std(response_times)*1000:.2f}ms\")\n",
    "    \n",
    "    return response_times\n",
    "\n",
    "# %%\n",
    "# Run performance test\n",
    "if api_healthy:\n",
    "    response_times = performance_test(num_requests=20)\n",
    "    \n",
    "    # Plot response time distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist([rt * 1000 for rt in response_times], bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.axvline(np.mean(response_times)*1000, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {np.mean(response_times)*1000:.2f}ms')\n",
    "    plt.xlabel('Response Time (ms)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('API Response Time Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. Error Case Testing\n",
    "\n",
    "# %%\n",
    "# Test error cases\n",
    "error_test_cases = {\n",
    "    \"missing_features\": {\n",
    "        \"customer_id\": \"ERROR_001\",\n",
    "        \"features\": {}  # Empty features\n",
    "    },\n",
    "    \"wrong_feature_type\": {\n",
    "        \"customer_id\": \"ERROR_002\",\n",
    "        \"features\": {\n",
    "            \"Year_mean\": \"2024\",  # String instead of number\n",
    "            \"Month_mean\": 6.0\n",
    "        }\n",
    "    },\n",
    "    \"extra_features\": {\n",
    "        \"customer_id\": \"ERROR_003\",\n",
    "        \"features\": {\n",
    "            \"Year_mean\": 2024.0,\n",
    "            \"Month_mean\": 6.0,\n",
    "            \"Extra_Feature\": 100.0  # Extra feature not expected by model\n",
    "        }\n",
    "    },\n",
    "    \"malformed_json\": \"This is not JSON\",  # Invalid JSON\n",
    "    \"null_values\": {\n",
    "        \"customer_id\": \"ERROR_004\",\n",
    "        \"features\": {\n",
    "            \"Year_mean\": None,  # Null value\n",
    "            \"Month_mean\": 6.0\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# %%\n",
    "print(\"\\nüß™ Testing Error Cases...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "error_results = {}\n",
    "\n",
    "for name, payload in error_test_cases.items():\n",
    "    print(f\"\\nTesting: {name}\")\n",
    "    \n",
    "    try:\n",
    "        if name == \"malformed_json\":\n",
    "            # Send raw string instead of JSON\n",
    "            response = requests.post(\n",
    "                PREDICT_ENDPOINT,\n",
    "                data=payload,\n",
    "                headers={\"Content-Type\": \"application/json\"},\n",
    "                timeout=10\n",
    "            )\n",
    "        else:\n",
    "            response = requests.post(\n",
    "                PREDICT_ENDPOINT,\n",
    "                json=payload,\n",
    "                headers={\"Content-Type\": \"application/json\"},\n",
    "                timeout=10\n",
    "            )\n",
    "        \n",
    "        error_results[name] = {\n",
    "            \"status_code\": response.status_code,\n",
    "            \"response\": response.json() if response.status_code != 200 else response.text[:100]\n",
    "        }\n",
    "        \n",
    "        print(f\"  Status: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code >= 400:\n",
    "            print(f\"  ‚úÖ Expected error (status {response.status_code})\")\n",
    "            if response.status_code == 400:\n",
    "                print(f\"  Detail: {response.json().get('detail', 'No detail')}\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  Unexpected success\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_results[name] = {\"error\": str(e)}\n",
    "        print(f\"  ‚ùå Exception: {e}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9. Create Test Report\n",
    "\n",
    "# %%\n",
    "def generate_test_report():\n",
    "    \"\"\"Generate comprehensive test report\"\"\"\n",
    "    report = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"api_base_url\": API_BASE_URL,\n",
    "        \"health_check\": \"PASSED\" if api_healthy else \"FAILED\",\n",
    "        \"test_summary\": {\n",
    "            \"total_test_cases\": len(sample_payloads),\n",
    "            \"successful_predictions\": sum(1 for r in all_results.values() if \"error\" not in r),\n",
    "            \"failed_predictions\": sum(1 for r in all_results.values() if \"error\" in r),\n",
    "            \"format_validation_passed\": sum(1 for v in validation_results.values() if v[\"valid\"]),\n",
    "            \"format_validation_failed\": sum(1 for v in validation_results.values() if not v[\"valid\"])\n",
    "        },\n",
    "        \"model_info\": model_info if 'model_info' in locals() else None,\n",
    "        \"sample_results\": {},\n",
    "        \"performance_metrics\": {},\n",
    "        \"error_cases\": error_results\n",
    "    }\n",
    "    \n",
    "    # Add sample results\n",
    "    for name, result in all_results.items():\n",
    "        if \"error\" not in result:\n",
    "            report[\"sample_results\"][name] = {\n",
    "                \"probability\": result.get(\"probability\"),\n",
    "                \"predicted_class\": result.get(\"predicted_class\"),\n",
    "                \"risk_category\": result.get(\"risk_category\"),\n",
    "                \"response_time_ms\": result.get(\"response_time_ms\")\n",
    "            }\n",
    "    \n",
    "    # Add performance metrics if available\n",
    "    if 'response_times' in locals():\n",
    "        report[\"performance_metrics\"] = {\n",
    "            \"avg_response_time_ms\": np.mean(response_times) * 1000,\n",
    "            \"min_response_time_ms\": np.min(response_times) * 1000,\n",
    "            \"max_response_time_ms\": np.max(response_times) * 1000,\n",
    "            \"std_dev_ms\": np.std(response_times) * 1000\n",
    "        }\n",
    "    \n",
    "    return report\n",
    "\n",
    "# %%\n",
    "# Generate and save test report\n",
    "test_report = generate_test_report()\n",
    "\n",
    "report_file = f\"../reports/api_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "os.makedirs(\"../reports\", exist_ok=True)\n",
    "\n",
    "with open(report_file, 'w') as f:\n",
    "    json.dump(test_report, f, indent=2)\n",
    "\n",
    "print(f\"\\nüìã Test report saved to: {report_file}\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ TEST SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"API Health: {'‚úÖ PASSED' if test_report['health_check'] == 'PASSED' else '‚ùå FAILED'}\")\n",
    "print(f\"Successful Predictions: {test_report['test_summary']['successful_predictions']}/{test_report['test_summary']['total_test_cases']}\")\n",
    "print(f\"Format Validation: {test_report['test_summary']['format_validation_passed']} passed, {test_report['test_summary']['format_validation_failed']} failed\")\n",
    "\n",
    "if test_report['performance_metrics']:\n",
    "    print(f\"Avg Response Time: {test_report['performance_metrics']['avg_response_time_ms']:.2f}ms\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10. Integration Test Suite\n",
    "\n",
    "# %%\n",
    "# Create a comprehensive integration test function\n",
    "def run_integration_test_suite():\n",
    "    \"\"\"Run complete integration test suite\"\"\"\n",
    "    print(\"üöÄ Running Integration Test Suite\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    test_results = []\n",
    "    \n",
    "    # Test 1: API Health\n",
    "    print(\"\\n1Ô∏è‚É£  Testing API Health...\")\n",
    "    health_ok = test_health_endpoint()\n",
    "    test_results.append((\"API Health\", health_ok))\n",
    "    \n",
    "    # Test 2: Model Info\n",
    "    print(\"\\n2Ô∏è‚É£  Testing Model Info...\")\n",
    "    if health_ok:\n",
    "        info = get_model_info()\n",
    "        test_results.append((\"Model Info\", info is not None))\n",
    "    \n",
    "    # Test 3: Basic Prediction\n",
    "    print(\"\\n3Ô∏è‚É£  Testing Basic Prediction...\")\n",
    "    if health_ok:\n",
    "        payload = sample_payloads[\"simple_test\"]\n",
    "        result = make_prediction(payload)\n",
    "        basic_pred_ok = \"error\" not in result\n",
    "        test_results.append((\"Basic Prediction\", basic_pred_ok))\n",
    "        \n",
    "        if basic_pred_ok:\n",
    "            print(f\"   Probability: {result.get('probability', 'N/A'):.4f}\")\n",
    "            print(f\"   Risk Category: {result.get('risk_category', 'N/A')}\")\n",
    "    \n",
    "    # Test 4: Response Format\n",
    "    print(\"\\n4Ô∏è‚É£  Testing Response Format...\")\n",
    "    if health_ok and basic_pred_ok:\n",
    "        errors = validate_response_format(result)\n",
    "        format_ok = len(errors) == 0\n",
    "        test_results.append((\"Response Format\", format_ok))\n",
    "        \n",
    "        if errors:\n",
    "            print(\"   Format Errors:\")\n",
    "            for error in errors:\n",
    "                print(f\"   - {error}\")\n",
    "    \n",
    "    # Test 5: Performance\n",
    "    print(\"\\n5Ô∏è‚É£  Testing Performance (5 requests)...\")\n",
    "    if health_ok:\n",
    "        try:\n",
    "            perf_times = performance_test(num_requests=5)\n",
    "            perf_ok = all(t < 1.0 for t in perf_times)  # All under 1 second\n",
    "            test_results.append((\"Performance\", perf_ok))\n",
    "        except:\n",
    "            test_results.append((\"Performance\", False))\n",
    "    \n",
    "    # Test 6: Error Handling\n",
    "    print(\"\\n6Ô∏è‚É£  Testing Error Handling...\")\n",
    "    error_payload = {\"customer_id\": \"TEST\", \"features\": {}}  # Missing features\n",
    "    error_result = make_prediction(error_payload)\n",
    "    error_ok = \"error\" in error_result or error_result.get(\"status_code\", 200) >= 400\n",
    "    test_results.append((\"Error Handling\", error_ok))\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä INTEGRATION TEST RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    passed = sum(1 for name, ok in test_results if ok)\n",
    "    total = len(test_results)\n",
    "    \n",
    "    for i, (name, ok) in enumerate(test_results, 1):\n",
    "        status = \"‚úÖ PASS\" if ok else \"‚ùå FAIL\"\n",
    "        print(f\"{i}. {name}: {status}\")\n",
    "    \n",
    "    print(f\"\\nOverall: {passed}/{total} tests passed ({passed/total*100:.1f}%)\")\n",
    "    \n",
    "    return passed == total\n",
    "\n",
    "# %%\n",
    "# Run the integration test suite\n",
    "all_tests_passed = run_integration_test_suite()\n",
    "\n",
    "if all_tests_passed:\n",
    "    print(\"\\nüéâ All integration tests passed! API is ready for production use.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Some integration tests failed. Please check the API implementation.\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 11. Example: Batch Prediction Script\n",
    "\n",
    "# %%\n",
    "# Example batch prediction script\n",
    "def batch_predict(csv_file_path: str, output_file: str = None):\n",
    "    \"\"\"\n",
    "    Make predictions for multiple customers from a CSV file.\n",
    "    \n",
    "    CSV should have columns matching feature names, plus optional 'customer_id'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read input data\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        \n",
    "        print(f\"Processing {len(df)} records...\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            # Prepare payload\n",
    "            customer_id = row.get('customer_id', f\"CUST_{idx+1:04d}\")\n",
    "            \n",
    "            # Extract features (exclude customer_id)\n",
    "            features = {col: row[col] for col in df.columns \n",
    "                       if col != 'customer_id' and pd.notna(row[col])}\n",
    "            \n",
    "            payload = {\n",
    "                \"customer_id\": customer_id,\n",
    "                \"features\": features\n",
    "            }\n",
    "            \n",
    "            # Make prediction\n",
    "            result = make_prediction(payload)\n",
    "            \n",
    "            if \"error\" not in result:\n",
    "                results.append({\n",
    "                    \"customer_id\": customer_id,\n",
    "                    \"probability\": result.get(\"probability\"),\n",
    "                    \"predicted_class\": result.get(\"predicted_class\"),\n",
    "                    \"risk_category\": result.get(\"risk_category\"),\n",
    "                    \"risk_score\": result.get(\"risk_score\"),\n",
    "                    \"recommendation\": result.get(\"recommendation\"),\n",
    "                    **features  # Include original features\n",
    "                })\n",
    "            else:\n",
    "                results.append({\n",
    "                    \"customer_id\": customer_id,\n",
    "                    \"error\": result.get(\"error\"),\n",
    "                    **features\n",
    "                })\n",
    "            \n",
    "            # Print progress\n",
    "            if (idx + 1) % 10 == 0 or (idx + 1) == len(df):\n",
    "                print(f\"  Processed {idx + 1}/{len(df)}...\", end=\"\\r\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Processed {len(df)} records\")\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        results_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Save to file if specified\n",
    "        if output_file:\n",
    "            results_df.to_csv(output_file, index=False)\n",
    "            print(f\"üìÑ Results saved to: {output_file}\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        successful = len([r for r in results if \"error\" not in r])\n",
    "        print(f\"\\nüìä Batch Summary:\")\n",
    "        print(f\"  Successful: {successful}/{len(df)}\")\n",
    "        print(f\"  Failed: {len(df) - successful}\")\n",
    "        \n",
    "        if successful > 0:\n",
    "            print(f\"  Avg probability: {results_df['probability'].mean():.4f}\")\n",
    "            risk_counts = results_df['risk_category'].value_counts()\n",
    "            for risk, count in risk_counts.items():\n",
    "                print(f\"  {risk}: {count} customers ({count/len(results_df)*100:.1f}%)\")\n",
    "        \n",
    "        return results_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Batch processing failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# %%\n",
    "# Example: Create sample CSV for batch testing\n",
    "sample_data = [\n",
    "    {\"customer_id\": \"BATCH_001\", \"Year_mean\": 2024.0, \"Month_mean\": 6.0},\n",
    "    {\"customer_id\": \"BATCH_002\", \"Year_mean\": 2023.0, \"Month_mean\": 3.0},\n",
    "    {\"customer_id\": \"BATCH_003\", \"Year_mean\": 2022.0, \"Month_mean\": 11.0},\n",
    "    {\"customer_id\": \"BATCH_004\", \"Year_mean\": 2024.0, \"Month_mean\": 8.0},\n",
    "    {\"customer_id\": \"BATCH_005\", \"Year_mean\": 2023.0, \"Month_mean\": 5.0}\n",
    "]\n",
    "\n",
    "sample_df = pd.DataFrame(sample_data)\n",
    "sample_csv_path = \"../payloads/batch_sample.csv\"\n",
    "sample_df.to_csv(sample_csv_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Created sample batch CSV: {sample_csv_path}\")\n",
    "print(\"\\nSample data:\")\n",
    "print(sample_df.to_string())\n",
    "\n",
    "# %%\n",
    "# Uncomment to run batch prediction (requires API to be running)\n",
    "# if api_healthy:\n",
    "#     batch_results = batch_predict(sample_csv_path, \"../reports/batch_results.csv\")\n",
    "#     print(\"\\nBatch results preview:\")\n",
    "#     print(batch_results[['customer_id', 'probability', 'risk_category', 'recommendation']].to_string())\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 12. API Client Class (for reuse in other projects)\n",
    "\n",
    "# %%\n",
    "class CreditRiskAPIClient:\n",
    "    \"\"\"Client class for Credit Risk Scoring API\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url: str = \"http://localhost:8001\"):\n",
    "        self.base_url = base_url\n",
    "        self.health_endpoint = f\"{base_url}/health\"\n",
    "        self.predict_endpoint = f\"{base_url}/predict\"\n",
    "        self.model_info_endpoint = f\"{base_url}/model-info\"\n",
    "        \n",
    "    def check_health(self) -> Dict:\n",
    "        \"\"\"Check API health\"\"\"\n",
    "        try:\n",
    "            response = requests.get(self.health_endpoint, timeout=5)\n",
    "            return {\n",
    "                \"healthy\": response.status_code == 200,\n",
    "                \"status_code\": response.status_code,\n",
    "                \"data\": response.json() if response.status_code == 200 else None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"healthy\": False, \"error\": str(e)}\n",
    "    \n",
    "    def get_model_info(self) -> Dict:\n",
    "        \"\"\"Get model information\"\"\"\n",
    "        try:\n",
    "            response = requests.get(self.model_info_endpoint, timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                return {\"success\": True, \"data\": response.json()}\n",
    "            else:\n",
    "                return {\"success\": False, \"error\": f\"Status {response.status_code}\"}\n",
    "        except Exception as e:\n",
    "            return {\"success\": False, \"error\": str(e)}\n",
    "    \n",
    "    def predict(self, features: Dict, customer_id: str = None) -> Dict:\n",
    "        \"\"\"Make a prediction\"\"\"\n",
    "        payload = {\"features\": features}\n",
    "        if customer_id:\n",
    "            payload[\"customer_id\"] = customer_id\n",
    "            \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.predict_endpoint,\n",
    "                json=payload,\n",
    "                headers={\"Content-Type\": \"application/json\"},\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return {\"success\": True, \"data\": response.json()}\n",
    "            else:\n",
    "                return {\n",
    "                    \"success\": False,\n",
    "                    \"status_code\": response.status_code,\n",
    "                    \"error\": response.text\n",
    "                }\n",
    "        except Exception as e:\n",
    "            return {\"success\": False, \"error\": str(e)}\n",
    "    \n",
    "    def batch_predict(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Make predictions for a DataFrame of features\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            customer_id = row.get('customer_id', f\"cust_{idx}\")\n",
    "            features = {col: row[col] for col in df.columns if col != 'customer_id'}\n",
    "            \n",
    "            result = self.predict(features, customer_id)\n",
    "            \n",
    "            if result[\"success\"]:\n",
    "                data = result[\"data\"]\n",
    "                results.append({\n",
    "                    \"customer_id\": customer_id,\n",
    "                    \"probability\": data.get(\"probability\"),\n",
    "                    \"predicted_class\": data.get(\"predicted_class\"),\n",
    "                    \"risk_category\": data.get(\"risk_category\"),\n",
    "                    \"risk_score\": data.get(\"risk_score\"),\n",
    "                    \"recommendation\": data.get(\"recommendation\"),\n",
    "                    **features\n",
    "                })\n",
    "            else:\n",
    "                results.append({\n",
    "                    \"customer_id\": customer_id,\n",
    "                    \"error\": result.get(\"error\"),\n",
    "                    **features\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "# %%\n",
    "# Example usage of the client class\n",
    "print(\"Testing API Client Class...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create client\n",
    "client = CreditRiskAPIClient(API_BASE_URL)\n",
    "\n",
    "# Test health\n",
    "health_result = client.check_health()\n",
    "print(f\"Health check: {'‚úÖ Healthy' if health_result.get('healthy') else '‚ùå Unhealthy'}\")\n",
    "\n",
    "if health_result.get('healthy'):\n",
    "    # Get model info\n",
    "    model_info = client.get_model_info()\n",
    "    if model_info.get('success'):\n",
    "        print(f\"Model: {model_info['data'].get('model_source', 'Unknown')}\")\n",
    "    \n",
    "    # Make a prediction\n",
    "    test_features = {\"Year_mean\": 2024.0, \"Month_mean\": 6.0}\n",
    "    prediction = client.predict(test_features, \"CLIENT_TEST_001\")\n",
    "    \n",
    "    if prediction.get('success'):\n",
    "        data = prediction['data']\n",
    "        print(f\"\\nPrediction Result:\")\n",
    "        print(f\"  Customer: {data.get('customer_id')}\")\n",
    "        print(f\"  Probability: {data.get('probability'):.4f}\")\n",
    "        print(f\"  Risk Category: {data.get('risk_category')}\")\n",
    "        print(f\"  Recommendation: {data.get('recommendation')}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Prediction failed: {prediction.get('error')}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Summary\n",
    "# \n",
    "# This notebook provides:\n",
    "# 1. ‚úÖ API connection testing\n",
    "# 2. ‚úÖ Sample payload generation\n",
    "# 3. ‚úÖ Response format validation\n",
    "# 4. ‚úÖ Performance testing\n",
    "# 5. ‚úÖ Error case testing\n",
    "# 6. ‚úÖ Integration test suite\n",
    "# 7. ‚úÖ Batch prediction example\n",
    "# 8. ‚úÖ Reusable API client class\n",
    "# \n",
    "# To use this notebook:\n",
    "# 1. Start your API: `docker-compose up -d`\n",
    "# 2. Update `API_BASE_URL` if needed\n",
    "# 3. Run the cells sequentially\n",
    "# 4. Check the generated reports in the `reports/` directory\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìö API Inference Testing Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Check generated reports in ../reports/\")\n",
    "print(\"2. Review any failed tests\")\n",
    "print(\"3. Use the API client class in your applications\")\n",
    "print(\"4. Extend test cases as needed for your specific use case\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
