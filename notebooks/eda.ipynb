{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894ce61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (EDA) Script\n",
    "# notebooks/eda.ipynb\n",
    "\n",
    "# Ensure required packages are installed in the notebook environment\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')  # so we can import the data_processing module\n",
    "\n",
    "\n",
    "# Robust import: \n",
    "try:\n",
    "\tfrom data_processing import DataLoader, EDA, DataProcessor\n",
    "except Exception:\n",
    "\timport importlib\n",
    "\ttry:\n",
    "\t\tdp = importlib.import_module('data_processing')\n",
    "\texcept Exception as ie:\n",
    "\t\traise ImportError(f\"Failed to import data_processing module from ../src: {ie}\") from ie\n",
    "\n",
    "\t# show what's available to help diagnose naming differences\n",
    "\tavailable = [n for n in dir(dp) if not n.startswith('_')]\n",
    "\tprint(\"Available in data_processing:\", available)\n",
    "\n",
    "\t# attempt to bind expected names (try common alternatives for DataProcessor)\n",
    "\tDataLoader = getattr(dp, 'DataLoader', None)\n",
    "\tEDA = getattr(dp, 'EDA', None)\n",
    "\tDataProcessor = getattr(dp, 'DataProcessor', None)\n",
    "\tif DataProcessor is None:\n",
    "\t\tfor alt in ('Processor', 'DataProc', 'DataProcessorClass', 'Data_Processor'):\n",
    "\t\t\tif hasattr(dp, alt):\n",
    "\t\t\t\tDataProcessor = getattr(dp, alt)\n",
    "\t\t\t\tprint(f\"Using alternative DataProcessor name: {alt}\")\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\tmissing = [name for name, obj in [('DataLoader', DataLoader), ('EDA', EDA), ('DataProcessor', DataProcessor)] if obj is None]\n",
    "\tif missing:\n",
    "\t\traise ImportError(f\"Could not import {missing} from data_processing. Check class names/exports. Available: {available}\")\n",
    "\n",
    "# Load raw data\n",
    "data_path = '../data/raw/data.csv'  # Change filename as needed\n",
    "loader = DataLoader(data_path)\n",
    "raw_df = loader.load_data()\n",
    "\n",
    "# Quick overview of the raw data\n",
    "raw_eda = EDA(raw_df)\n",
    "print(\"Raw data preview:\")\n",
    "print(raw_eda.dataset_overview()['preview'])\n",
    "print()\n",
    "print(\"Raw missing values (diagnostics):\")\n",
    "from IPython.display import display, Markdown\n",
    "raw_miss = raw_eda.missing_values_table()\n",
    "\n",
    "# suggestion map can be used when we have missing-value info to annotate suggestions\n",
    "suggestion_map = {\n",
    "\t'none': 'No action needed',\n",
    "\t'median': 'Impute numeric values with median',\n",
    "\t'median_or_model': 'Impute with median or consider model-based imputation',\n",
    "\t'consider_drop_or_model': 'Consider dropping or using model-based imputation',\n",
    "\t'mode': 'Impute categorical values with mode',\n",
    "\t'mode_with_flag': 'Impute with mode and add missing flag',\n",
    "\t'consider_drop_or_new_category': 'Consider dropping column or create a new category'\n",
    "}\n",
    "\n",
    "if raw_miss.empty:\n",
    "\tdisplay(Markdown('**Missing Values:** None detected — no NA values found in the raw dataset.'))\n",
    "\t# define an empty disp DataFrame so later code that expects `disp` won't fail\n",
    "\tdisp = pd.DataFrame(columns=['Missing', 'Percent', 'Dtype', 'Nunique', 'Sample', 'Suggestion'])\n",
    "else:\n",
    "\tdisp = raw_miss.copy()\n",
    "\tdisp['Percent'] = disp['Percent'].map(lambda x: f'{x:.1f}%')\n",
    "\tdisp['Sample'] = disp['Sample'].map(lambda s: ', '.join(map(str, s)) if isinstance(s, (list, tuple)) else str(s))\n",
    "\tdisp['Suggestion_Explanation'] = disp['Suggestion'].map(suggestion_map)\n",
    "\n",
    "display(disp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e1b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Summary Statistics\n",
    "print(\"\\nSummary Statistics:\\n\", raw_eda.summary_statistics())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946d32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Numerical Feature Distributions\n",
    "num_cols = raw_df.select_dtypes(include=np.number).columns.tolist()\n",
    "# pick a few if there are many\n",
    "num_cols = num_cols[:6] if len(num_cols) > 6 else num_cols\n",
    "print('Numeric columns to plot:', num_cols)\n",
    "raw_eda.plot_numerical_distributions(num_cols=num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Categorical Feature Distributions\n",
    "cat_cols = raw_df.select_dtypes(include='object').columns.tolist()\n",
    "cat_cols = cat_cols[:6] if len(cat_cols) > 6 else cat_cols\n",
    "print('Categorical columns to plot:', cat_cols)\n",
    "# Plot each categorical column. For very high-cardinality columns show top-20 only\n",
    "for col in cat_cols:\n",
    "    nuniq = raw_df[col].nunique(dropna=True)\n",
    "    if nuniq <= 50:\n",
    "        # reasonable cardinality -> full bar plot\n",
    "        raw_eda.plot_categorical_distributions(cat_cols=[col], max_unique=50)\n",
    "    else:\n",
    "        print(f'Column {col} has high cardinality ({nuniq}). Showing top 20 values only.')\n",
    "        ax = raw_df[col].value_counts().head(20).plot(kind='bar', figsize=(10,3))\n",
    "        ax.set_title(f'Top 20 values for {col}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c60131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Correlation Analysis\n",
    "corr = raw_eda.correlation_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4631ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Missing Values\n",
    "print(\"\\nMissing Values Table (raw):\\n\", raw_eda.missing_values_table())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fbcc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. Outlier Detection\n",
    "raw_eda.boxplot_outliers(num_cols=num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ad1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Processing (Task 2): normalize missing values and create processed dataset\n",
    "proc = DataProcessor(raw_df)\n",
    "# Use default processing config; customize as needed:\n",
    "cfg = DataProcessor.ProcessConfig()\n",
    "processed_df = proc.process(cfg)\n",
    "processed_eda = EDA(processed_df)\n",
    "\n",
    "print('Processed data preview:')\n",
    "print(processed_eda.dataset_overview()['preview'])\n",
    "\n",
    "print('Missing values (processed):')\n",
    "from IPython.display import display, Markdown\n",
    "proc_miss = processed_eda.missing_values_table()\n",
    "if proc_miss.empty:\n",
    "    display(Markdown('**Missing Values (processed):** None detected — preprocessing handled NA values.'))\n",
    "else:\n",
    "    disp2 = proc_miss.copy()\n",
    "    disp2['Percent'] = disp2['Percent'].map(lambda x: f'{x:.1f}%')\n",
    "    disp2['Sample'] = disp2['Sample'].map(lambda s: ', '.join(map(str, s)) if isinstance(s, (list, tuple)) else str(s))\n",
    "    # reuse suggestion_map defined earlier if present, else create fallback\n",
    "    try:\n",
    "        disp2['Suggestion_Explanation'] = disp2['Suggestion'].map(suggestion_map)\n",
    "    except NameError:\n",
    "        disp2['Suggestion_Explanation'] = disp2['Suggestion']\n",
    "    display(disp2)\n",
    "\n",
    "# Compare missing counts before / after for visualization\n",
    "raw_miss = raw_eda.missing_values_table()\n",
    "proc_miss = processed_eda.missing_values_table()\n",
    "cmp = raw_miss[['Missing']].rename(columns={'Missing':'RawMissing'})\n",
    "if not proc_miss.empty:\n",
    "    cmp = cmp.join(proc_miss['Missing'].rename('ProcMissing'), how='left')\n",
    "else:\n",
    "    cmp['ProcMissing'] = 0\n",
    "cmp.fillna(0, inplace=True)\n",
    "\n",
    "if not cmp.empty:\n",
    "    ax = cmp.sort_values('RawMissing', ascending=False).head(20).plot(kind='bar', figsize=(10,4))\n",
    "    ax.set_xlabel('Column')\n",
    "    ax.set_ylabel('Missing count')\n",
    "    ax.set_title('Missing values: raw vs processed (top 20)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469a020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save processed and create a train/test split under repo-root data/processed/\n",
    "out_path = proc.save_processed('../data/processed/processed_data.csv')\n",
    "\n",
    "print('Processed data saved to', os.path.abspath(out_path))\n",
    "\n",
    "# Provide explicit split paths that point to repo-root `data/processed/`\n",
    "split_cfg = DataProcessor.SplitConfig(train_path='../data/processed/train.csv', test_path='../data/processed/test.csv')\n",
    "train_path, test_path = proc.split_save(split_cfg)\n",
    "print('Train/Test saved to', os.path.abspath(train_path), os.path.abspath(test_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181033ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-generate Top Insights from processed data (data-driven)\n",
    "from IPython.display import Markdown, display\n",
    "import numpy as np\n",
    "\n",
    "# Prefer processed DataFrame in memory, else try reading the processed CSV, else use raw_df\n",
    "if 'proc' in globals() and getattr(proc, 'df', None) is not None:\n",
    "    df_inspect = proc.df.copy()\n",
    "elif os.path.exists('../data/processed/processed_data.csv'):\n",
    "    df_inspect = pd.read_csv('../data/processed/processed_data.csv')\n",
    "else:\n",
    "    df_inspect = raw_df.copy()\n",
    "\n",
    "n_rows, n_cols = df_inspect.shape\n",
    "numeric_cols = df_inspect.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = df_inspect.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# 1) Data concentration in categorical columns\n",
    "concentrated = []\n",
    "for c in cat_cols:\n",
    "    top_share = df_inspect[c].value_counts(dropna=True, normalize=True).iloc[0] if df_inspect[c].dropna().shape[0] > 0 else 0\n",
    "    if top_share >= 0.5:\n",
    "        concentrated.append((c, float(top_share), df_inspect[c].value_counts().index[0]))\n",
    "\n",
    "# 2) Missing value summary\n",
    "miss = df_inspect.isnull().sum()\n",
    "miss_pct = (miss / max(1, n_rows) * 100).round(1)\n",
    "miss_table = pd.DataFrame({'Missing': miss, 'Percent': miss_pct})\n",
    "miss_table = miss_table[miss_table['Missing'] > 0].sort_values('Missing', ascending=False)\n",
    "top_missing = miss_table.head(5)\n",
    "\n",
    "# 3) Outlier detection (z-score heuristic)\n",
    "outlier_counts = {}\n",
    "for c in numeric_cols:\n",
    "    col = df_inspect[c].dropna()\n",
    "    if col.shape[0] > 0 and col.std(ddof=0) > 0:\n",
    "        z = (col - col.mean()) / col.std(ddof=0)\n",
    "        outlier_counts[c] = int((z.abs() > 3).sum())\n",
    "    else:\n",
    "        outlier_counts[c] = 0\n",
    "outliers_df = pd.Series(outlier_counts).sort_values(ascending=False).rename('OutlierCount')\n",
    "top_outliers = outliers_df[outliers_df > 0].head(5)\n",
    "\n",
    "# 4) Strong correlations among numeric features\n",
    "corr_pairs = []\n",
    "if len(numeric_cols) >= 2:\n",
    "    corr = df_inspect[numeric_cols].corr().abs()\n",
    "    for i, a in enumerate(corr.columns):\n",
    "        for b in corr.columns[i+1:]:\n",
    "            val = corr.loc[a, b]\n",
    "            if pd.notna(val) and val >= 0.7:\n",
    "                corr_pairs.append((a, b, float(val)))\n",
    "    corr_pairs = sorted(corr_pairs, key=lambda x: -x[2])\n",
    "\n",
    "# 5) Categorical diversity (high-cardinality columns)\n",
    "cat_card = [(c, int(df_inspect[c].nunique(dropna=True))) for c in cat_cols]\n",
    "cat_card_sorted = sorted(cat_card, key=lambda x: -x[1])\n",
    "\n",
    "# Build human-friendly insights\n",
    "insights_lines = []\n",
    "insights_lines.append(f\"**Dataset:** {n_rows:,} rows × {n_cols:,} columns.\")\n",
    "\n",
    "if concentrated:\n",
    "    for c, share, topv in concentrated:\n",
    "        insights_lines.append(f\"**Concentration:** `{c}` is concentrated: top value `{topv}` covers {share*100:.1f}% of non-null rows.\")\n",
    "else:\n",
    "    insights_lines.append(\"**Concentration:** No categorical column has a single value covering >=50% of non-null rows.\")\n",
    "\n",
    "if not top_missing.empty:\n",
    "    rows = [f\"`{idx}`: {int(r['Missing']):,} ({r['Percent']}%)\" for idx, r in top_missing.iterrows()]\n",
    "    insights_lines.append(\"**Missing values (top columns):** \" + \"; \".join(rows))\n",
    "else:\n",
    "    insights_lines.append(\"**Missing values:** No missing values detected after processing.\")\n",
    "\n",
    "if not top_outliers.empty:\n",
    "    out_rows = [f\"`{idx}`: {int(cnt)} outliers\" for idx, cnt in top_outliers.items()]\n",
    "    insights_lines.append(\"**Outliers (z-score > 3), top numeric columns:** \" + \"; \".join(out_rows))\n",
    "else:\n",
    "    insights_lines.append(\"**Outliers:** No extreme outliers (z-score > 3) found in numeric columns.\")\n",
    "\n",
    "if corr_pairs:\n",
    "    top_corr = \", \".join([f\"`{a}`↔`{b}`={val:.2f}\" for a, b, val in corr_pairs[:5]])\n",
    "    insights_lines.append(\"**Strong correlations (|r|>=0.7):** \" + top_corr)\n",
    "else:\n",
    "    insights_lines.append(\"**Correlations:** No strong correlations (|r|>=0.7) found among numeric features.\")\n",
    "\n",
    "if cat_card_sorted:\n",
    "    top_high = cat_card_sorted[:3]\n",
    "    top_low = sorted(cat_card_sorted, key=lambda x: x[1])[:3]\n",
    "    insights_lines.append(\"**Categorical diversity:** top high-cardinality columns: \" + \", \".join([f\"`{c}`({n})\" for c, n in top_high]))\n",
    "    insights_lines.append(\"**Categorical diversity:** top low-cardinality columns: \" + \", \".join([f\"`{c}`({n})\" for c, n in top_low]))\n",
    "\n",
    "# Display\n",
    "display(Markdown(\"### Top EDA Insights (data-driven)\"))\n",
    "for line in insights_lines:\n",
    "    display(Markdown(f\"- {line}\"))\n",
    "\n",
    "# Also show supporting small tables for quick inspection\n",
    "if not miss_table.empty:\n",
    "    display(Markdown('**Missing values (top 10)**'))\n",
    "    display(miss_table.head(10))\n",
    "if not top_outliers.empty:\n",
    "    display(Markdown('**Outlier counts (top numeric columns)**'))\n",
    "    display(top_outliers.head(10))\n",
    "if corr_pairs:\n",
    "    display(Markdown('**Strong correlation pairs (|r|>=0.7)**'))\n",
    "    display(pd.DataFrame(corr_pairs, columns=['feature_a', 'feature_b', 'abs_corr']).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a23c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
